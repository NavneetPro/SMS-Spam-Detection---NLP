{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugcBmX_pYmWn",
        "outputId": "f4695896-3b16-4381-f0ef-9fa8895ce91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg6ChBx7YxLO",
        "outputId": "d4c31292-29d7-4701-a7e8-ff64d74ea552"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGgSfwMYxb_",
        "outputId": "b709465b-14ce-4cc4-a3f7-e22a0ffd8511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import textwrap as tw\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "import joblib\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Token\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "from spellchecker import SpellChecker"
      ],
      "metadata": {
        "id": "1SSork_CYxeq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKEyoRWXYxhP",
        "outputId": "4ffc8132-2ca8-4d94-8356-75445c7fe262"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = Path('/content/drive/MyDrive/NLP')"
      ],
      "metadata": {
        "id": "dPeodjzfYxkC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj9XbEWWZzWX",
        "outputId": "e4ad2b2d-f8b1-4e8b-adab-bc439093e172"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-15 14:47:52.281029: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 231 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "9N8Qb_jQYxm4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_file = data_folder / 'spam.csv'"
      ],
      "metadata": {
        "id": "1tQ4if9JYxp2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Dataframe\n",
        "spam = pd.read_csv(spam_file, index_col=0,encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "ZyfO4XK3Yxsy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of data set is : {spam.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58UNwoI7Yxvq",
        "outputId": "03245b74-740a-44fb-a791-8a099e0d6751"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data set is : (5572, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "YSHc7QQVYxyq",
        "outputId": "1fb362bd-942f-4615-f75c-ba77afd29732"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     v2 Unnamed: 2 Unnamed: 3  \\\n",
              "v1                                                                              \n",
              "ham   Go until jurong point, crazy.. Available only ...        NaN        NaN   \n",
              "ham                       Ok lar... Joking wif u oni...        NaN        NaN   \n",
              "spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN        NaN   \n",
              "ham   U dun say so early hor... U c already then say...        NaN        NaN   \n",
              "ham   Nah I don't think he goes to usf, he lives aro...        NaN        NaN   \n",
              "\n",
              "     Unnamed: 4  \n",
              "v1               \n",
              "ham         NaN  \n",
              "ham         NaN  \n",
              "spam        NaN  \n",
              "ham         NaN  \n",
              "ham         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dac20853-c9e5-4d25-987c-541ef390ddf2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dac20853-c9e5-4d25-987c-541ef390ddf2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dac20853-c9e5-4d25-987c-541ef390ddf2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dac20853-c9e5-4d25-987c-541ef390ddf2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JsVenbtYx1r",
        "outputId": "11131d38-f28f-4fed-cece-fee6c1e4a0cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5572 entries, ham to ham\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v2          5572 non-null   object\n",
            " 1   Unnamed: 2  50 non-null     object\n",
            " 2   Unnamed: 3  12 non-null     object\n",
            " 3   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(4)\n",
            "memory usage: 217.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam.drop(columns = ['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "spam.reset_index(inplace=True)\n",
        "spam.rename(columns={'v1':'label', 'v2':'message'},inplace=True)"
      ],
      "metadata": {
        "id": "3ZxnCi65Yx6Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "swJCkPTDYx9p",
        "outputId": "ce9d405b-d6d1-4b68-d8b2-c14c05be4a92"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8d34e72-c814-4372-9984-e58e4fce5528\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8d34e72-c814-4372-9984-e58e4fce5528')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8d34e72-c814-4372-9984-e58e4fce5528 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8d34e72-c814-4372-9984-e58e4fce5528');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "spam.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDxfQvSHYyAw",
        "outputId": "b80a0ef4-20da-4330-a45a-a2bba7114a52"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label      0\n",
              "message    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking distribution of class labels for train dataset\n",
        "spam['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn1wt_iXbSV9",
        "outputId": "c93004ff-ffe4-44f6-8b5d-f5788c34f2a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     0.865937\n",
              "spam    0.134063\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking distribution of class labels for train dataset\n",
        "spam['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R00VkW_CbU_2",
        "outputId": "ca67a089-1e31-45fa-8570-cfdd3683b327"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_folder = Path('/content/drive/MyDrive/NLP/saved_models')"
      ],
      "metadata": {
        "id": "YpYRxoY2bYx3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using accuracy as the metric is not optimal to making the best prediction especially due to the fact that our data set is imbalanced\n",
        "\n",
        "#To achieve an optimal result we would like to maximize two components:\n",
        "\n",
        "#(1) The \"True Positive Rate\" aka Sensitivity aka Recall. Given by: TP/(TP+FN)\n",
        "\n",
        "#(2) The Precision - How many of the positive predictions, are in fact correct. Given by: TP/(TP+FP)\n",
        "\n",
        "#To obtain a balance between both we use F Beta Measure which is given by: (2 x Precision x Recall)/(Precision+Recall)\n",
        "#F2-measure puts more attention on increasing reacall and minimizing false negatives which is critical for our problem statement given that we would not want to miss any actual spam messages."
      ],
      "metadata": {
        "id": "WayBSjrVcKjY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a scorer for F2 score so that we can given an emphases on the minority class predictions i.e higher recall\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "f2score = make_scorer(fbeta_score, beta=2)\n",
        "f2score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrYb0dQAcXkw",
        "outputId": "a3d8cc7f-a4e6-4bbc-fa59-7898b99abccf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "make_scorer(fbeta_score, beta=2)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam['label'] = spam['label'].map({'spam':1, 'ham':0}).astype(int)"
      ],
      "metadata": {
        "id": "dH2jaL7gcnnH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gmmYenALiM3e",
        "outputId": "d1703388-2c58-48c9-e45d-cda203cf2bda"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                            message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ab3b969-1283-40c2-bd09-51069d41aed0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab3b969-1283-40c2-bd09-51069d41aed0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ab3b969-1283-40c2-bd09-51069d41aed0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ab3b969-1283-40c2-bd09-51069d41aed0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL** **PIPELINE**"
      ],
      "metadata": {
        "id": "9606fYkKgTKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning behind choosing Final Pipeline**\n",
        "\n",
        "In File 1, We created three different models:\n",
        "\n",
        "Model 1 : # Data Preprocessing + Sparse Embeddings (TF-IDF) + ML Model pipeline\n",
        "\n",
        "Model 2: #Featurization (TF-IDF) + Feature Engineering + ML Model pipeline\n",
        "\n",
        "Model 3: #Feature Engineering + ML Model pipeline \n",
        "\n",
        "Now we had to choose amongst these for the final pipeline. In this case we want a model which is better at generalising the result. \n",
        "\n",
        "Hence we consider the model with the Best Cross Validation Score as our final model. \n",
        "\n",
        "In our case Model 1 even though shows overfitting had the highest cross validation score of 0.65. Hence I have choosen Model 1 as the final pipeline."
      ],
      "metadata": {
        "id": "NSYLvpkigYaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 40% of data\n",
        "spam_smaller = spam.sample(frac=0.4, replace=True, random_state=1)"
      ],
      "metadata": {
        "id": "tz6_OHtncrh8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = spam_smaller['message'].values\n",
        "y = spam_smaller['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
        "print(f'X_train: {X_train.shape} y_train: {y_train.shape}')\n",
        "print(f'X_test: {X_test.shape} y_test: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATRUYoeYdB4T",
        "outputId": "0d6eb5a5-2ba9-40c9-cc94-61a7b15bfdc5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (1671,) y_train: (1671,)\n",
            "X_test: (558,) y_test: (558,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Custom Classes"
      ],
      "metadata": {
        "id": "0eimlbpudB6_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpacyPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    np.random.seed(0)\n",
        "    def __init__(self, lammetize=True, lower=True, remove_stop=True, \n",
        "                 remove_punct=True, remove_email=True, remove_url=True, remove_num=False, stemming = False,\n",
        "                 add_user_mention_prefix=True, remove_hashtag_prefix=False):\n",
        "        self.remove_stop = remove_stop\n",
        "        self.remove_punct = remove_punct\n",
        "        self.remove_num = remove_num\n",
        "        self.remove_url = remove_url\n",
        "        self.remove_email = remove_email\n",
        "        self.lammetize = lammetize\n",
        "        self.lower = lower\n",
        "        self.stemming = stemming\n",
        "        self.add_user_mention_prefix = add_user_mention_prefix\n",
        "        self.remove_hashtag_prefix = remove_hashtag_prefix\n",
        "\n",
        " # helpfer functions for basic cleaning \n",
        "\n",
        "    def basic_clean(self, text):\n",
        "        \n",
        "        '''\n",
        "        This fuction removes HTML tags from text\n",
        "        '''\n",
        "        if (bool(BeautifulSoup(text, \"html.parser\").find())==True):         \n",
        "            soup = BeautifulSoup(text, \"html.parser\")\n",
        "            text = soup.get_text()\n",
        "        else:\n",
        "            pass\n",
        "        return re.sub(r'[\\n\\r]',' ', text) \n",
        "\n",
        "    # helper function for pre-processing with spacy and Porter Stemmer\n",
        "    \n",
        "    def spacy_preprocessor(self,texts):\n",
        "\n",
        "        final_result = []\n",
        "        nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
        "        \n",
        "        ## Add @ as a prefix so that we can separate the word from its token\n",
        "        prefixes = list(nlp.Defaults.prefixes)\n",
        "\n",
        "        if self.add_user_mention_prefix:\n",
        "            prefixes += ['@']\n",
        "\n",
        "        ## Remove # as a prefix so that we can keep hashtags and words together\n",
        "        if self.remove_hashtag_prefix:\n",
        "            prefixes.remove(r'#')\n",
        "\n",
        "        prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
        "        nlp.tokenizer.prefix_search = prefix_regex.search\n",
        "\n",
        "        matcher = Matcher(nlp.vocab)\n",
        "        if self.remove_stop:\n",
        "            matcher.add(\"stop_words\", [[{\"is_stop\" : True}]])\n",
        "        if self.remove_punct:\n",
        "            matcher.add(\"punctuation\",[ [{\"is_punct\": True}]])\n",
        "        if self.remove_num:\n",
        "            matcher.add(\"numbers\", [[{\"like_num\": True}]])\n",
        "        if self.remove_url:\n",
        "            matcher.add(\"urls\", [[{\"like_url\": True}]])\n",
        "        if self.remove_email:\n",
        "            matcher.add(\"emails\", [[{\"like_email\": True}]])\n",
        "            \n",
        "        Token.set_extension('is_remove', default=False, force=True)\n",
        "\n",
        "        cleaned_text = []\n",
        "        for doc in nlp.pipe(texts,batch_size= 500,disable=['parser','ner'], n_process = 3):\n",
        "            matches = matcher(doc)\n",
        "            for _, start, end in matches:\n",
        "                for token in doc[start:end]:\n",
        "                    token._.is_remove =True\n",
        "                    \n",
        "            if self.lammetize:              \n",
        "                text = ' '.join(token.lemma_ for token in doc if (token._.is_remove==False))\n",
        "            elif self.stemming:\n",
        "                text = ' '.join(PorterStemmer().stem(token.text) for token in doc if (token._.is_remove==False))\n",
        "            else:\n",
        "                text = ' '.join(token.text for token in doc if (token._.is_remove==False))\n",
        "                                   \n",
        "            if self.lower:\n",
        "                text=text.lower()\n",
        "            cleaned_text.append(text)\n",
        "        return cleaned_text\n",
        "\n",
        "    def fit(self, X,y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        try:\n",
        "            if str(type(X)) not in [\"<class 'list'>\",\"<class 'numpy.ndarray'>\"]:\n",
        "                raise Exception('Expected list or numpy array got {}'.format(type(X)))\n",
        "            x_clean = [self.basic_clean(text) for text in X]\n",
        "            x_clean_final = self.spacy_preprocessor(x_clean)\n",
        "            return x_clean_final\n",
        "        except Exception as error:\n",
        "            print('An exception occured: ' + repr(error))"
      ],
      "metadata": {
        "id": "VCAU3j2fdB96"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
        "    np.random.seed(0)\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
        "    spell = SpellChecker()\n",
        "    def __init__(self, word_count=False, char_count=False, char_count_wo_space=False, \n",
        "                 avg_word_length=False, digit_count=False, noun_count= True, propernoun_count=True, \n",
        "                 verb_count=True, aux_count= True, adj_count= True, ner_count= True, misspelled_count=True):\n",
        "        self.word_count = word_count\n",
        "        self.char_count = char_count\n",
        "        self.char_count_wo_space = char_count_wo_space\n",
        "        self.avg_word_length = avg_word_length\n",
        "        self.digit_count = digit_count\n",
        "        self.noun_count = noun_count\n",
        "        self.propernoun_count = propernoun_count\n",
        "        self.verb_count = verb_count\n",
        "        self.aux_count = aux_count\n",
        "        self.adj_count = adj_count\n",
        "        self.ner_count = ner_count\n",
        "        self.misspelled_count= misspelled_count\n",
        "  \n",
        "    def fit(self, X,y=None):\n",
        "        return self\n",
        "\n",
        "    #Useful functions\n",
        "\n",
        "    def wordCount(self,text):\n",
        "        return len(text.split())\n",
        "\n",
        "    def charCount(self,text):\n",
        "        return len(text)\n",
        "\n",
        "    def charCountWithoutSpace(self,text):\n",
        "        count = 0\n",
        "        for word in text.split():\n",
        "            count += len(word)\n",
        "        return count\n",
        "\n",
        "    def avgWordLength(self,text):\n",
        "        word_length = 0\n",
        "        for token in text.split():\n",
        "            word_length += len(token)\n",
        "        word_count = len(text.split())\n",
        "        if word_count == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return word_length/word_count\n",
        "\n",
        "    def digitCount(self,text):\n",
        "        count = 0\n",
        "        for i in text:\n",
        "            if i.isdigit():\n",
        "                count += 1\n",
        "        return count\n",
        "\n",
        "    \n",
        "\n",
        "    def nouncount(self, text):\n",
        "      doc = nlp(text)\n",
        "      noun_tokens = [token.text for token in doc if(token.pos_== 'NOUN')]        \n",
        "      return len(noun_tokens)\n",
        "\n",
        "    def propernouncount(self, text):\n",
        "      doc = nlp(text)\n",
        "      prnoun_tokens = [token.text for token in doc if(token.pos_== 'PROPN')]       \n",
        "      return len(prnoun_tokens)\n",
        "    \n",
        "    def verbcount(self, text):\n",
        "      doc = nlp(text)\n",
        "      verb_tokens = [token.text for token in doc if(token.pos_== 'VERB')]         \n",
        "      return len(verb_tokens)\n",
        "    \n",
        "    def auxcount(self, text):\n",
        "      doc = nlp(text)\n",
        "      aux_tokens = [token.text for token in doc if(token.pos_== 'AUX')]        \n",
        "      return len(aux_tokens)\n",
        "\n",
        "    def adjcount(self, text):\n",
        "      doc = nlp(text)\n",
        "      adj_tokens = [token.text for token in doc if(token.pos_== 'ADJ')]        \n",
        "      return len(adj_tokens)\n",
        "\n",
        "    def nercount(self, text):\n",
        "      doc = nlp(text)\n",
        "      ner = [entity.text for entity in doc.ents]       \n",
        "      return len(ner)\n",
        "\n",
        "    def misspelledcount(self,text):\n",
        "      doc = nlp(text)\n",
        "      tokens = [token.text for token in doc]\n",
        "      misspelled_tokens = SpellChecker().unknown(tokens)       \n",
        "      return len(misspelled_tokens)\n",
        "\n",
        "    def transform(self, X,y=None):\n",
        "        try:\n",
        "            if str(type(X)) not in [\"<class 'list'>\",\"<class 'numpy.ndarray'>\"]:\n",
        "                raise Exception('Expected list or numpy array got {}'.format(type(X)))\n",
        "            final_result = []\n",
        "            for index,item in enumerate(X):\n",
        "                res = []\n",
        "                if self.word_count:\n",
        "                    res.append(self.wordCount(item))\n",
        "                if self.char_count:\n",
        "                    res.append(self.charCount(item))\n",
        "                if self.char_count_wo_space:\n",
        "                    res.append(self.charCountWithoutSpace(item))\n",
        "                if self.avg_word_length:\n",
        "                    res.append(self.avgWordLength(item))\n",
        "                if self.digit_count:\n",
        "                    res.append(self.digitCount(item))\n",
        "                if self.noun_count:\n",
        "                    res.append(self.nouncount(item))\n",
        "                if self.propernoun_count:\n",
        "                    res.append(self.propernouncount(item))\n",
        "                if self.verb_count:\n",
        "                    res.append(self.verbcount(item))\n",
        "                if self.aux_count:\n",
        "                    res.append(self.auxcount(item))\n",
        "                if self.adj_count:\n",
        "                    res.append(self.adjcount(item))\n",
        "                if self.ner_count:\n",
        "                    res.append(self.nercount(item))\n",
        "                if self.misspelled_count:\n",
        "                    res.append(self.misspelledcount(item))\n",
        "                final_result.append(res)\n",
        "            return np.array(final_result)\n",
        "        except Exception as error:\n",
        "            print('An exception occured: ' + repr(error))\n"
      ],
      "metadata": {
        "id": "sZtSKwtWdCA2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseTransformer(TransformerMixin):\n",
        "\n",
        "  def fit(self, X, y=None, **fit_params):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X, y=None, **fit_params):\n",
        "      return X.todense()"
      ],
      "metadata": {
        "id": "RxLBKe6ddCD7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 2 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : estimator instance\n",
        "        An estimator instance implementing `fit` and `predict` methods which\n",
        "        will be cloned for each validation.\n",
        "\n",
        "    title : str\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "        Training vector, where ``n_samples`` is the number of samples and\n",
        "        ``n_features`` is the number of features.\n",
        "\n",
        "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
        "        Target relative to ``X`` for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array-like of shape (3,), default=None\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple of shape (2,), default=None\n",
        "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, default=None\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, default=None\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like of shape (n_ticks,)\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
        "        as a fraction of the maximum size of the training set (that is\n",
        "        determined by the selected validation method), i.e. it has to be within\n",
        "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
        "        sets. Note that for classification the number of samples usually have\n",
        "        to be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "    if axes is None:\n",
        "        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    axes[0].set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes[0].set_ylim(*ylim)\n",
        "    axes[0].set_xlabel(\"Training examples\")\n",
        "    axes[0].set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True,\n",
        "                       random_state=123)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes[0].grid()\n",
        "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "\n",
        "    # Plot n_samples vs fit_times\n",
        "    axes[1].grid()\n",
        "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
        "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
        "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
        "    axes[1].set_xlabel(\"Training examples\")\n",
        "    axes[1].set_ylabel(\"fit_times\")\n",
        "    axes[1].set_title(\"Scalability of the model\")\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "Le2y8ObMdCHG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count examples in each class\n",
        "counter = Counter(spam_smaller['label'])\n",
        "counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Yc1sl5hEni",
        "outputId": "190d8243-3f18-4bc7-bac0-369d74ef0c0d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 1956, 1: 273})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# estimate scale_pos_weight value\n",
        "estimate = counter[0] / counter[1]"
      ],
      "metadata": {
        "id": "Ull2Y-3yhTHn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier_1 = Pipeline([('preprocessor', SpacyPreprocessor(remove_stop=False, remove_email=False, remove_url=False )),\n",
        "                  ('vectorizer', TfidfVectorizer(analyzer='word', token_pattern=r\"[\\S]+\")),\n",
        "                  ('classifier', XGBClassifier(scale_pos_weight=estimate))\n",
        "                 ])"
      ],
      "metadata": {
        "id": "8sDo4RWKwC0B"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_classifier_1 = {'preprocessor__lammetize' : [True, False],\n",
        "                'vectorizer__max_features': [100, 500, None],\n",
        "                'vectorizer__max_df': [0.2, 0.8, 1],\n",
        "                'vectorizer__min_df': [0.01,0.5, 1]\n",
        "                }"
      ],
      "metadata": {
        "id": "p-7QDvXIwC3L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gridserach to  fine tune hyperparameters using cross validation\n",
        "# As we have imbalanced data set, we will use scoring method of f2score.\n",
        "grid_classifier_1 = GridSearchCV(estimator=Classifier_1, param_grid=param_grid_classifier_1, cv = 2, scoring= f2score, n_jobs= 1, verbose = 4)"
      ],
      "metadata": {
        "id": "TPSikQBmwC6L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on training data\n",
        "grid_classifier_1.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70EXQYG8wC9b",
        "outputId": "98d06b06-cd5c-4f06-c707-40cc2b16f2bb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.807 total time=   6.9s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.830 total time=   6.5s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.7s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.6s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.789 total time=   7.6s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.827 total time=   7.5s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.806 total time=   6.5s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.805 total time=   8.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.6s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.8s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.771 total time=   7.8s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.830 total time=   7.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.806 total time=   7.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.805 total time=   7.0s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.740 total time=   6.9s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.794 total time=   6.9s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.864 total time=   7.0s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.840 total time=   6.7s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.858 total time=   6.6s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.840 total time=   7.1s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.837 total time=   7.1s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.832 total time=   6.7s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.800 total time=   6.7s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.863 total time=   7.9s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.837 total time=   7.7s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.832 total time=   6.7s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.792 total time=   7.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.842 total time=   6.9s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.140 total time=   7.5s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.154 total time=  11.5s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=nan total time=   6.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=nan total time=   4.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.2s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   4.2s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.279 total time=  11.7s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.252 total time=   6.7s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   4.4s\n",
            "[CV 1/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.297 total time=   7.6s\n",
            "[CV 2/2] END preprocessor__lammetize=True, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.266 total time=   7.2s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.775 total time=   6.7s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.869 total time=   6.7s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.820 total time=   7.7s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.854 total time=   8.1s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.807 total time=   8.8s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.775 total time=   7.5s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.6s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.801 total time=   9.0s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.833 total time=   8.0s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.807 total time=   6.7s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.775 total time=   7.9s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   4.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   4.1s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.744 total time=   7.1s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.2, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.688 total time=   8.7s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.825 total time=   7.8s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=0.833 total time=   8.6s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   4.0s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.6s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.832 total time=   7.4s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.838 total time=   8.0s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.846 total time=   8.4s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=0.846 total time=   7.4s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   4.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.8s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.835 total time=   8.5s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.833 total time=  10.2s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.846 total time=   8.0s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=0.846 total time=   8.0s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   4.1s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.7s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.765 total time=   8.6s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.810 total time=   8.0s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=nan total time=   3.7s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.01;, score=nan total time=   3.3s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=0.5;, score=nan total time=   3.8s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.162 total time=   7.5s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=100, vectorizer__min_df=1;, score=0.060 total time=   8.5s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=nan total time=   4.0s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.01;, score=nan total time=   3.7s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.8s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=0.5;, score=nan total time=   3.8s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.291 total time=   8.8s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=500, vectorizer__min_df=1;, score=0.252 total time=   8.9s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=nan total time=   3.7s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.01;, score=nan total time=   3.4s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.3s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=0.5;, score=nan total time=   3.4s\n",
            "[CV 1/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.297 total time=   6.9s\n",
            "[CV 2/2] END preprocessor__lammetize=False, vectorizer__max_df=1, vectorizer__max_features=None, vectorizer__min_df=1;, score=0.276 total time=   6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "48 fits failed out of a total of 108.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "36 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 2077, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1344, in fit_transform\n",
            "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
            "ValueError: max_df corresponds to < documents than min_df\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 2077, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1348, in fit_transform\n",
            "    X, vocabulary, max_doc_count, min_doc_count, max_features\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1180, in _limit_features\n",
            "    \"After pruning, no terms remain. Try a lower min_df or a higher max_df.\"\n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.81879084        nan 0.80827068 0.80521147        nan 0.80046983\n",
            " 0.80521147        nan 0.76700795 0.85210421        nan 0.84873407\n",
            " 0.83415836        nan 0.83157018 0.83415836        nan 0.81663327\n",
            "        nan        nan 0.14678166        nan        nan 0.26536705\n",
            "        nan        nan 0.28119628 0.82195983        nan 0.837295\n",
            " 0.79137045        nan 0.81705729 0.79137045        nan 0.7159834\n",
            " 0.82924034        nan 0.83481996 0.84615555        nan 0.8341617\n",
            " 0.84615555        nan 0.78729376        nan        nan 0.111139\n",
            "        nan        nan 0.27156066        nan        nan 0.28633286]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[('preprocessor',\n",
              "                                        SpacyPreprocessor(remove_email=False,\n",
              "                                                          remove_stop=False,\n",
              "                                                          remove_url=False)),\n",
              "                                       ('vectorizer',\n",
              "                                        TfidfVectorizer(token_pattern='[\\\\S]+')),\n",
              "                                       ('classifier',\n",
              "                                        XGBClassifier(scale_pos_weight=7.164835164835165))]),\n",
              "             n_jobs=1,\n",
              "             param_grid={'preprocessor__lammetize': [True, False],\n",
              "                         'vectorizer__max_df': [0.2, 0.8, 1],\n",
              "                         'vectorizer__max_features': [100, 500, None],\n",
              "                         'vectorizer__min_df': [0.01, 0.5, 1]},\n",
              "             scoring=make_scorer(fbeta_score, beta=2), verbose=4)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best cross-validation score: {:.2f}\".format(grid_classifier_1.best_score_))\n",
        "print(\"\\nBest parameters: \", grid_classifier_1.best_params_)\n",
        "print(\"\\nBest Estimator: \", grid_classifier_1.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K_7pdqTwDAb",
        "outputId": "c14ee709-6da2-40ef-fd78-155a43fc521d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best cross-validation score: 0.85\n",
            "\n",
            "Best parameters:  {'preprocessor__lammetize': True, 'vectorizer__max_df': 0.8, 'vectorizer__max_features': 100, 'vectorizer__min_df': 0.01}\n",
            "\n",
            "Best Estimator:  Pipeline(steps=[('preprocessor',\n",
            "                 SpacyPreprocessor(remove_email=False, remove_stop=False,\n",
            "                                   remove_url=False)),\n",
            "                ('vectorizer',\n",
            "                 TfidfVectorizer(max_df=0.8, max_features=100, min_df=0.01,\n",
            "                                 token_pattern='[\\\\S]+')),\n",
            "                ('classifier',\n",
            "                 XGBClassifier(scale_pos_weight=7.164835164835165))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train score: {:.4f}'.format(grid_classifier_1.score(X_train, y_train)))\n",
        "print('Test score: {:.4f}'.format(grid_classifier_1.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTNU0BHOwZsc",
        "outputId": "fb165f21-3f04-4be8-9b3a-cbb5708dd09c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.9535\n",
            "Test score: 0.8651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted values for Test data set\n",
        "y_test_pred = grid_classifier_1.predict(X_test)"
      ],
      "metadata": {
        "id": "MvMBc28yxNG_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nTest set classification report:\\n\\n',classification_report(y_test, y_test_pred ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkyigh3SxSV4",
        "outputId": "018abb7c-e472-4eca-d177-10ac4eb9e4dd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set classification report:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       490\n",
            "           1       0.86      0.87      0.86        68\n",
            "\n",
            "    accuracy                           0.97       558\n",
            "   macro avg       0.92      0.92      0.92       558\n",
            "weighted avg       0.97      0.97      0.97       558\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOpPoF6_ywVH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}